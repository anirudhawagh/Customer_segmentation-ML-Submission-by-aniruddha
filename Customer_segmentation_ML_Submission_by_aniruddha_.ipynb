{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anirudhawagh/Customer_segmentation-ML-Submission-by-aniruddha/blob/main/Customer_segmentation_ML_Submission_by_aniruddha_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "customer segmentation\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA/Regression/Classification/Unsupervised\n",
        "##### **Contribution**    - Individual\n",
        "##### **Name** - Aniruddha Wagh"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project focused on Online Retail Customer Segmentation, a critical aspect of modern business strategy. By categorizing customers into distinct groups based on their unique characteristics, valuable insights were gained to tailor approaches and meet specific segment needs.\n",
        "\n",
        "The study analyzed a UK-based online retail company specializing in all-occasion gifts, using a comprehensive dataset from 01/12/2010 to 09/12/2011, covering transactions of individual customers and wholesalers.\n",
        "\n",
        "Cutting-edge techniques, including the powerful Recency-Frequency-Monetary (RFM) model and advanced clustering algorithms like K-Means, Agglomerative Hierarchical Clustering, and DBSCAN, effectively segmented the customer base.\n",
        "\n",
        "The project involved essential steps like data inspection, insightful exploratory data analysis (EDA), meticulous data preparation, and successful implementation of the RFM model and clustering algorithms.\n",
        "\n",
        "These efforts yielded profound insights into customer behavior, guiding targeted marketing strategies and elevating customer satisfaction.\n",
        "\n",
        "To sum up, this project showcased advanced proficiency in data analysis and customer segmentation, providing businesses with the means to enhance their offerings and excel in the fiercely competitive online retail industry.\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " GitHub Link -https://github.com/anirudhawagh/Customer_segmentation-ML-Submission-by-aniruddha"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, your task is to identify major customer segments on a transnational data set which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail.The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import math\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "pd.set_option('display.max_columns', 500)\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "import missingno as msno\n",
        "\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "import matplotlib.cm as cm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "sB4154bcat0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "Customer_df = pd.read_excel( \"/content/drive/MyDrive/Online Retail.xlsx\")\n"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Customer_df.head()"
      ],
      "metadata": {
        "id": "3ppTNcsmCQ8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "Customer_df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "# Get the number of rows and columns\n",
        "num_rows, num_columns = Customer_df.shape\n",
        "\n",
        "# Print the counts\n",
        "print(\"Number of rows:\", num_rows)\n",
        "print(\"Number of columns:\", num_columns)"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "Customer_df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get the names of all the columns\n",
        "column_names = Customer_df.columns.tolist()\n",
        "\n",
        "# Print the names of all the columns in vertical format\n",
        "print(\"Column names:\")\n",
        "for column_name in column_names:\n",
        "    print(column_name)\n",
        "\n",
        "# Get the total number of columns\n",
        "num_columns = Customer_df.shape[1]\n",
        "\n",
        "# Print the total number of columns\n",
        "print(\"Total number of columns:\", num_columns)"
      ],
      "metadata": {
        "id": "p1oSuPgKH6--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "# Count the duplicate rows in the DataFrame\n",
        "duplicate_count = Customer_df.duplicated().sum()\n",
        "\n",
        "# Print the count of duplicate rows\n",
        "print(\"Number of duplicate rows in the dataset:\", duplicate_count)"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Use duplicated() with keep=False to mark all duplicates as True\n",
        "duplicate_mask = Customer_df.duplicated(keep=False)\n",
        "\n",
        "# Use boolean indexing to get the duplicate rows\n",
        "duplicate_rows = Customer_df[duplicate_mask]\n",
        "\n",
        "# Print the duplicate rows\n",
        "print(\"Duplicate Rows:\")\n",
        "print(duplicate_rows)"
      ],
      "metadata": {
        "id": "s54oPOKcIrq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Step 1: Get the missing column names and their respective missing percentages\n",
        "missing = Customer_df.columns[Customer_df.isnull().any()].tolist()\n",
        "missing_percentages = round(Customer_df[missing].isnull().mean() * 100, 2)\n",
        "\n",
        "# Step 2: Create a DataFrame to store the missing information\n",
        "missing_df = pd.DataFrame({'Missing Count': Customer_df[missing].isnull().sum(), 'Missing Percentage': missing_percentages})\n",
        "\n",
        "# Print the missing information for columns with missing values\n",
        "print(missing_df)\n"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import missingno as msno\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Set a dark background style for the plot\n",
        "plt.style.use('dark_background')\n",
        "\n",
        "# Create the missing value matrix plot with blue color\n",
        "msno.matrix(Customer_df, figsize=(10, 6), sparkline=False, color=(0.15, 0.35, 0.75))\n",
        "\n",
        "# Customize plot\n",
        "plt.title('Missing Value Matrix', fontsize=16, color='white')\n",
        "plt.xlabel('Features', fontsize=12, color='white')\n",
        "plt.ylabel('Samples', fontsize=12, color='white')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Overview:\n",
        "\n",
        "Captures all transactions from 01/12/2010 to 09/12/2011 for a UK-based and registered non-store online retail specializing in unique all-occasion gifts, with a substantial wholesale customer base.\n",
        "Data Size:\n",
        "\n",
        "Contains an impressive 541,909 rows and 8 columns.\n",
        "Data Types:\n",
        "\n",
        "2 columns are of float64 data type.\n",
        "1 column is of int64 data type.\n",
        "4 columns are of object data type.\n",
        "1 column is of datetime64 data type.\n",
        "Duplicated Values:\n",
        "\n",
        "A total of 5,268 duplicated values are found, representing 24.93% of the dataset.\n",
        "Missing Data:\n",
        "\n",
        "The \"CustomerID\" column has a missing data percentage of 24.93%.\n",
        "The \"Description\" column has a negligible 0.27% of missing data.\n",
        "Prepare to be captivated as we delve into the insights hidden within this remarkable dataset!"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "columns_list =Customer_df.columns.tolist()\n",
        "\n",
        "\n",
        "for column in columns_list:\n",
        "    print(column)"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "Customer_df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Certainly! Here's a rephrased version of the description of each column:\n",
        "\n",
        "- **InvoiceNo:** This column contains a unique transaction number assigned to each purchase. It's a 6-digit integral number, including the 'c' prefix for cancellations.\n",
        "\n",
        "- **StockCode:** The StockCode column contains a 5-digit integral number that uniquely identifies each product in the inventory.\n",
        "\n",
        "- **Description:** The Description column provides a brief textual representation of the purchased product.\n",
        "\n",
        "- **Quantity:** In this column, you'll find the quantity of each product bought in a transaction. It's represented as an integer, showing the number of units purchased.\n",
        "\n",
        "- **InvoiceDate:** This column holds the date and time of each transaction, offering insights into the timing and frequency of customer purchases.\n",
        "\n",
        "- **UnitPrice:** The UnitPrice column displays the cost of a single unit of the product in the local currency.\n",
        "\n",
        "- **CustomerID:** This column consists of a unique identifier assigned to each customer, enabling the tracking of individual customer behavior and preferences.\n",
        "\n",
        "- **Country:** The Country column records the country where each customer resides or where the transaction occurred, providing geographic location information."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "unique_values = {}\n",
        "for column in Customer_df.columns:\n",
        "    unique_values[column] = Customer_df[column].unique()\n",
        "\n",
        "for column, values in unique_values.items():\n",
        "    print(f\"Unique values for {column}:\")\n",
        "    print(values)\n",
        "    print(\"=\"*30)\n",
        "\n",
        "    # Check Unique Values for each variable.\n",
        "\n",
        "for i in Customer_df.columns.tolist():\n",
        "  print(\"Number of unique values in\",i,\"is\",Customer_df[i].nunique())\n"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove rows with missing values in 'CustomerID' column\n",
        "Customer_df.dropna(subset=['CustomerID'], inplace=True)\n",
        "\n",
        "# Check for any missing values in the dataset\n",
        "missing_values = Customer_df.isnull().sum()\n",
        "print(\"Missing Values:\")\n",
        "print(missing_values)\n",
        "\n"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop all the duplicate values in the dataset\n",
        "Customer_df.drop_duplicates(inplace = True)\n",
        "\n",
        "# Check for any duplicate values in the dataset\n",
        "Customer_df.duplicated().sum()"
      ],
      "metadata": {
        "id": "TiMcNOFn8Uws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataframe have negative valiues in quantity.\n",
        "#Here we observed that Invoice number starting with C has negative values and as per description of the data those are cancelations. so we need to drop this entries.\n",
        "Customer_df[Customer_df['Quantity']<0]"
      ],
      "metadata": {
        "id": "HJXG-Axa9EXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# changing the datatype to str\n",
        "Customer_df['InvoiceNo'] = Customer_df['InvoiceNo'].astype('str')"
      ],
      "metadata": {
        "id": "AmTQGwKkyIyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# also If InvoiceNo starts with C means it's a cancellation. We need to drop this entries.\n",
        "Customer_df=Customer_df[~Customer_df['InvoiceNo'].str.contains('C')]"
      ],
      "metadata": {
        "id": "dNbipGLDyUyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking how many values are present for unitprice==0\n",
        "# almost 40 values are present so will drop this values\n",
        "len(Customer_df[Customer_df['UnitPrice']==0])"
      ],
      "metadata": {
        "id": "uw3epNPdylS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Customer_df['InvoiceDate'] = pd.to_datetime(Customer_df['InvoiceDate'])\n",
        "\n",
        "# Create a new column 'Weekday' with values 1 for weekdays and 0 for weekends\n",
        "Customer_df['Weekday'] = Customer_df['InvoiceDate'].dt.dayofweek // 5\n",
        "\n",
        "# Display the first few rows of the DataFrame to verify the new column\n",
        "print(Customer_df.head())"
      ],
      "metadata": {
        "id": "qVwhHiuJbNq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# taking unitprice values greater than 0.\n",
        "Customer_df=Customer_df[Customer_df['UnitPrice']>0]\n",
        "Customer_df.head()"
      ],
      "metadata": {
        "id": "SS8KbfFdyxGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the top 10 selling products in horizontal format\n",
        "top_products = Customer_df.groupby('Description')['Quantity'].sum().sort_values(ascending=False).head(10)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=top_products.values, y=top_products.index, palette='viridis')\n",
        "plt.xlabel('Total Quantity Sold')\n",
        "plt.ylabel('Product Description')\n",
        "plt.title('Top 10 Selling Products')\n",
        "plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n",
        "plt.show()\n",
        "\n",
        "# Create a table showing the actual selling product numbers\n",
        "product_numbers = pd.DataFrame({'Product Description': top_products.index, 'Total Quantity Sold': top_products.values})\n",
        "product_numbers.index += 1\n",
        "print(\"Top 10 Selling Products:\")\n",
        "print(product_numbers)\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by product and sum the quantities\n",
        "bottom_products = Customer_df.groupby('Description')['Quantity'].sum().sort_values(ascending=True).head(10)\n",
        "\n",
        "# Plot the least selling products in horizontal format\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=bottom_products.values, y=bottom_products.index, palette='viridis')\n",
        "plt.xlabel('Total Quantity Sold')\n",
        "plt.ylabel('Product Description')\n",
        "plt.title('Least Selling Products')  # Updated title\n",
        "plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n",
        "plt.show()\n",
        "\n",
        "# Create a table showing the actual selling product numbers\n",
        "product_numbers = pd.DataFrame({'Product Description': bottom_products.index, 'Total Quantity Sold': bottom_products.values})\n",
        "product_numbers.index += 1\n",
        "print(\"Least Selling Products:\")  # Updated title\n",
        "print(product_numbers)\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by product and count the number of orders\n",
        "frequently_ordered_products = Customer_df.groupby('Description')['InvoiceNo'].count().sort_values(ascending=False).head(10)\n",
        "\n",
        "# Create a bar plot for frequently ordered products\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=frequently_ordered_products.values, y=frequently_ordered_products.index, palette='viridis')\n",
        "plt.xlabel('Number of Orders')\n",
        "plt.ylabel('Product Description')\n",
        "plt.title('Top 10 Frequently Ordered Products')\n",
        "plt.show()\n",
        "\n",
        "# Create a table for frequently ordered products\n",
        "frequently_ordered_table = pd.DataFrame({'Product Description': frequently_ordered_products.index, 'Number of Orders': frequently_ordered_products.values})\n",
        "frequently_ordered_table.index += 1\n",
        "print(\"Top 10 Frequently Ordered Products:\")\n",
        "print(frequently_ordered_table)\n"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by Country and sum the total monetary value of transactions\n",
        "country_total_sales = Customer_df.groupby('Country')['UnitPrice'].sum()\n",
        "\n",
        "# Get the top 5 countries with maximum sales\n",
        "top_countries = country_total_sales.sort_values(ascending=False).head(5)\n",
        "\n",
        "# Plot the top 5 countries with maximum sales\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=top_countries.index, y=top_countries.values, palette='viridis')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Total Sales')\n",
        "plt.title('Top 5 Countries with Maximum Sales')\n",
        "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
        "plt.show()\n",
        "\n",
        "# Create a table showing the top 5 countries with maximum sales\n",
        "top_countries_table = pd.DataFrame({'Country': top_countries.index, 'Total Sales': top_countries.values})\n",
        "top_countries_table.index += 1\n",
        "print(\"Top 5 Countries with Maximum Sales:\")\n",
        "print(top_countries_table)\n"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by Country and sum the total monetary value of transactions\n",
        "country_total_sales = Customer_df.groupby('Country')['UnitPrice'].sum()\n",
        "\n",
        "# Get the top 5 countries with maximum sales\n",
        "top_countries = country_total_sales.sort_values(ascending=False).head(5)\n",
        "\n",
        "# Plot the top 5 countries with maximum sales\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=top_countries.index, y=top_countries.values, palette='viridis')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Total Sales')\n",
        "plt.title('Top 5 Countries with Maximum Sales')\n",
        "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
        "plt.show()\n",
        "\n",
        "# Create a table showing the top 5 countries with maximum sales\n",
        "top_countries_table = pd.DataFrame({'Country': top_countries.index, 'Total Sales': top_countries.values})\n",
        "top_countries_table.index += 1\n",
        "print(\"Top 5 Countries with Maximum Sales:\")\n",
        "print(top_countries_table)\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import calendar\n",
        "import pandas as pd\n",
        "\n",
        "# Extract the month from the InvoiceDate and create a new 'Month' column\n",
        "Customer_df['Month'] = Customer_df['InvoiceDate'].dt.month\n",
        "\n",
        "# Group by Month and count the number of sales\n",
        "sales_by_month = Customer_df.groupby('Month')['InvoiceNo'].count()\n",
        "\n",
        "# Map month numbers to month names\n",
        "sales_by_month.index = sales_by_month.index.map(lambda x: calendar.month_name[x])\n",
        "\n",
        "# Plot the sales count in different months\n",
        "plt.figure(figsize=(12, 6))\n",
        "sales_by_month.plot(kind='bar', color='skyblue')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Sales Count')\n",
        "plt.title('Sales Count in Different Months')\n",
        "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
        "plt.show()\n",
        "\n",
        "# Create a table showing the actual sales count for each month\n",
        "sales_by_month_table = pd.DataFrame({'Month': sales_by_month.index, 'Sales Count': sales_by_month.values})\n",
        "sales_by_month_table.index += 1\n",
        "print(\"Sales Count in Different Months:\")\n",
        "print(sales_by_month_table)\n"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Extract the day of the week from the InvoiceDate and create a new 'DayOfWeek' column\n",
        "Customer_df['DayOfWeek'] = Customer_df['InvoiceDate'].dt.dayofweek\n",
        "\n",
        "# Define day names for mapping\n",
        "day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        "\n",
        "# Group by DayOfWeek and count the number of sales\n",
        "sales_by_day = Customer_df.groupby('DayOfWeek')['InvoiceNo'].count()\n",
        "\n",
        "# Map day numbers to day names\n",
        "sales_by_day.index = sales_by_day.index.map(lambda x: day_names[x])\n",
        "\n",
        "# Plot the sales count according to the days of the week\n",
        "plt.figure(figsize=(10, 6))\n",
        "sales_by_day.plot(kind='bar', color='skyblue')\n",
        "plt.xlabel('Day of the Week')\n",
        "plt.ylabel('Sales Count')\n",
        "plt.title('Sales Count According to Days of the Week')\n",
        "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
        "plt.show()\n",
        "\n",
        "# Create a table showing the actual sales count for each day of the week\n",
        "sales_by_day_table = pd.DataFrame({'Day of the Week': sales_by_day.index, 'Sales Count': sales_by_day.values})\n",
        "sales_by_day_table.index += 1\n",
        "print(\"Sales Count According to Days of the Week:\")\n",
        "print(sales_by_day_table)\n"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "# Define time intervals for different day timings\n",
        "time_intervals = {\n",
        "    'Morning': (6, 12),\n",
        "    'Afternoon': (12, 18),\n",
        "    'Evening': (18, 24)\n",
        "}\n",
        "\n",
        "# Define colors for each time interval\n",
        "time_colors = {\n",
        "    'Morning': 'skyblue',\n",
        "    'Afternoon': 'orange',\n",
        "    'Evening': 'green'\n",
        "}\n",
        "\n",
        "# Extract the hour from the InvoiceDate and create a new 'Hour' column\n",
        "Customer_df['Hour'] = Customer_df['InvoiceDate'].dt.hour\n",
        "\n",
        "# Function to categorize hours into time intervals\n",
        "def categorize_time(hour):\n",
        "    for interval, (start, end) in time_intervals.items():\n",
        "        if start <= hour < end:\n",
        "            return interval\n",
        "\n",
        "# Apply the categorize_time function to create a new 'TimeInterval' column\n",
        "Customer_df['TimeInterval'] = Customer_df['Hour'].apply(categorize_time)\n",
        "\n",
        "# Group by TimeInterval and count the number of sales\n",
        "sales_by_time = Customer_df.groupby('TimeInterval')['InvoiceNo'].count()\n",
        "\n",
        "# Plot the sales count in different day timings with different colors\n",
        "plt.figure(figsize=(10, 6))\n",
        "sales_by_time.plot(kind='bar', color=[time_colors[interval] for interval in sales_by_time.index])\n",
        "plt.xlabel('Time Interval')\n",
        "plt.ylabel('Sales Count')\n",
        "plt.title('Sales Count in Different Day Timings')\n",
        "plt.xticks(rotation=0)  # Keep x-axis labels horizontal\n",
        "\n",
        "# Create custom legend for time intervals and their colors\n",
        "handles = [plt.Rectangle((0,0),1,1, color=time_colors[interval]) for interval in sales_by_time.index]\n",
        "labels = sales_by_time.index\n",
        "plt.legend(handles, labels, loc='upper right')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Create a table showing the actual sales count for each day timing\n",
        "sales_by_time_table = pd.DataFrame({'Time Interval': sales_by_time.index, 'Sales Count': sales_by_time.values})\n",
        "sales_by_time_table.index += 1\n",
        "print(\"Sales Count in Different Day Timings:\")\n",
        "print(sales_by_time_table)\n"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by CustomerID and count the number of transactions\n",
        "top_customers = Customer_df['CustomerID'].value_counts().head(10)\n",
        "\n",
        "# Create a bar plot for top 10 customer IDs\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=top_customers.index, y=top_customers.values, palette='viridis')\n",
        "plt.xlabel('Customer ID')\n",
        "plt.ylabel('Number of Transactions')\n",
        "plt.title('Top 10 Customer IDs by Transaction Count')\n",
        "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
        "plt.show()\n",
        "\n",
        "# Create a table for top 10 customer IDs\n",
        "top_customers_table = pd.DataFrame({'Customer ID': top_customers.index, 'Transaction Count': top_customers.values})\n",
        "top_customers_table.index += 1\n",
        "print(\"Top 10 Customer IDs by Transaction Count:\")\n",
        "print(top_customers_table)\n"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = Customer_df.corr()\n",
        "\n",
        "# Create a heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=.5)\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set the style of the plot\n",
        "sns.set(style=\"ticks\", color_codes=True)\n",
        "\n",
        "# Create a pair plot with kernel density estimates on the diagonal\n",
        "pairplot = sns.pairplot(Customer_df, diag_kind='kde', palette='viridis')\n",
        "\n",
        "# Set the title for the pair plot\n",
        "pairplot.fig.suptitle(\"Explore Relationships with Pair Plot\", y=1.02)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1\n",
        "Hypothetical Statement 1: Customers who make purchases on weekdays have higher average spending compared to those who make purchases on weekends."
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hypothesis Testing 1:\n",
        "Null Hypothesis (H0): There is no significant difference in average spending between purchases made on weekdays and weekends.\n",
        "Alternative Hypothesis (H1): There is a significant difference in average spending between purchases made on weekdays and weekends."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_ind\n",
        "\n",
        "weekday_spending = Customer_df[Customer_df['Weekday'] == 1]['UnitPrice']\n",
        "weekend_spending = Customer_df[Customer_df['Weekday'] == 0]['UnitPrice']\n",
        "\n",
        "t_statistic, p_value = ttest_ind(weekday_spending, weekend_spending)\n",
        "alpha = 0.05\n",
        "print(p_value)\n",
        "\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference in spending between weekdays and weekends.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant difference in spending between weekdays and weekends.\")\n"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " I used the t-test (Student's t-test) to obtain the p-value. The t-test is a common statistical test used to determine if there is a significant difference between the means of two groups. In this context, I used the t-test to compare the average spending of two groups weekday spending vs. weekend spending"
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For comparing the average spending between purchases made on weekdays and weekends, I chose the independent t-test. This is because we are comparing the means of two independent groups (weekday spending vs. weekend spending), and the t-test is suitable for this scenario. The data is assumed to be continuous and approximately normally distributed."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2\n",
        "There is a significant difference in the average spending of the top 10 customers and the rest of the customers."
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): There is no significant difference in average spending between the top 10 customers and the rest of the customers.\n",
        "Alternative Hypothesis (H1): There is a significant difference in average spending between the top 10 customers and the rest of the customers."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the top 10 customer IDs based on their spending\n",
        "top_10_customers = Customer_df.groupby('CustomerID')['UnitPrice'].sum().sort_values(ascending=False).head(10).index\n",
        "\n",
        "# Extract spending data for top 10 customers and the rest\n",
        "top10_spending = Customer_df[Customer_df['CustomerID'].isin(top_10_customers)]['UnitPrice']\n",
        "rest_spending = Customer_df[~Customer_df['CustomerID'].isin(top_10_customers)]['UnitPrice']\n",
        "\n",
        "# Perform t-test\n",
        "t_statistic, p_value = ttest_ind(top10_spending, rest_spending)\n",
        "\n",
        "# Define significance level\n",
        "alpha = 0.05\n",
        "print (p_value),\n",
        "# Interpret results\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference in average spending between top 10 customers and the rest.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant difference in average spending between top 10 customers and the rest.\")\n"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To obtain the p-value, I performed an independent two-sample t-test. This test is suitable for comparing the means of two independent groups, which is the case when comparing the average spending of the top 10 customers and the rest of the customers. The p-value resulting from the t-test helps us assess whether the observed difference in average spending is statistically significant or if it could have occurred due to random chance"
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The reason I chose the independent two-sample t-test is because it's the right tool for comparing the spending patterns of the top 10 customers with the rest. This test helps answer whether the spending behavior of these two groups significantly differs.\n",
        "\n",
        "To put it simply, the t-test is designed for comparing averages of two groups, which fits our question perfectly. It works well with numerical data like spending amounts and is robust even if some assumptions aren't perfectly met. Given our specific research focus and data characteristics, the t-test was the logical choice to provide meaningful insights into potential spending disparities between the top 10 customers and the rest."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3\n",
        "Hypothetical Statement 3: The average spending of customers from the United Kingdom is different from the average spending of customers from other countries."
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): There is no significant difference in average spending between customers from the United Kingdom and customers from other countries.\n",
        "Alternative Hypothesis (H1): There is a significant difference in average spending between customers from the United Kingdom and customers from other countries."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "uk_spending = Customer_df[Customer_df['Country'] == 'United Kingdom']['UnitPrice']\n",
        "other_countries_spending = Customer_df[Customer_df['Country'] != 'United Kingdom']['UnitPrice']\n",
        "\n",
        "t_statistic, p_value = ttest_ind(uk_spending, other_countries_spending)\n",
        "alpha = 0.05\n",
        "print (p_value),\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference in average spending between customers from the United Kingdom and other countries.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant difference in average spending between customers from the United Kingdom and other countries.\")\n"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To obtain the p-value, I performed an independent two-sample t-test. This test is suitable for comparing the means of two independent groups, which is the case when comparing the average spending of customers from the United Kingdom is different from the average spending of customers from other countries.. The p-value resulting from the t-test helps us assess whether the observed difference in average spending is statistically significant or if it could have occurred due to random chance"
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose the independent two-sample t-test to compare the average spending of customers from the United Kingdom and other countries in my project. This test is ideal for evaluating differences between two groups' means. After calculating the p-value, if it's below 0.05, it indicates a significant difference. In this case, the p-value was very low, so I rejected the null hypothesis. This means there's indeed a meaningful distinction in average spending between UK and non-UK customers. The t-test's suitability for comparing two independent groups' means made it the right choice for addressing this specific hypothesis."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "missing_values = Customer_df.isnull().sum()\n",
        "print(missing_values)"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Customer_df['TotalCost'] = Customer_df['Quantity'] * Customer_df['UnitPrice']\n",
        "Customer_df.head()"
      ],
      "metadata": {
        "id": "A056bAlMUepH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Customer_df['Date'] = Customer_df['InvoiceDate'].dt.date\n",
        "Customer_df.head()"
      ],
      "metadata": {
        "id": "ctOJ51PPUznM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "# Get the number of rows and columns\n",
        "num_rows, num_columns = Customer_df.shape\n",
        "\n",
        "# Print the counts\n",
        "print(\"Number of rows:\", num_rows)\n",
        "print(\"Number of columns:\", num_columns)"
      ],
      "metadata": {
        "id": "1Ndn8EyqU7hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get the names of all the columns\n",
        "column_names = Customer_df.columns.tolist()\n",
        "\n",
        "# Print the names of all the columns in vertical format\n",
        "print(\"Column names:\")\n",
        "for column_name in column_names:\n",
        "    print(column_name)\n",
        "\n",
        "# Get the total number of columns\n",
        "num_columns = Customer_df.shape[1]\n",
        "\n",
        "# Print the total number of columns\n",
        "print(\"Total number of columns:\", num_columns)"
      ],
      "metadata": {
        "id": "VUdTxA4kVS7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the new 'TotalCost' feature\n",
        "Customer_df['TotalCost'] = Customer_df['Quantity'] * Customer_df['UnitPrice']\n",
        "\n",
        "# Display the first few rows of the DataFrame to verify the new feature\n",
        "print(Customer_df.head())"
      ],
      "metadata": {
        "id": "RoAjl-dCbddW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Customer_df['InvoiceDate'] = pd.to_datetime(Customer_df['InvoiceDate'])\n",
        "\n",
        "# Extract the date component and create the new 'Date' feature\n",
        "Customer_df['Date'] = Customer_df['InvoiceDate'].dt.date\n",
        "\n",
        "# Display the first few rows of the DataFrame to verify the new feature\n",
        "print(Customer_df.head())"
      ],
      "metadata": {
        "id": "arjSIT4Bb7_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. RFM Analysis**"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RFM analysis is a widely utilized customer segmentation technique in marketing and customer relationship management. RFM stands for Recency, Frequency, and Monetary Value – three vital dimensions employed to assess customer behavior and categorize customers based on their buying patterns. Here's a breakdown of each aspect:\n",
        "\n",
        "Recency (R): Recency pertains to the duration since a customer's last purchase. It gauges how recently a customer engaged with the business. Customers making recent purchases are often viewed as more engaged and responsive to marketing initiatives.\n",
        "\n",
        "Frequency (F): Frequency signifies the count of purchases a customer made within a defined timeframe. It gauges the level of customer activity. Customers with higher purchase frequencies are often more loyal and can be targeted for tailored marketing campaigns.\n",
        "\n",
        "Monetary Value (M): Monetary Value quantifies the total money a customer spent over a specific period. It showcases the customer's spending capacity and contribution to revenue. Customers with higher monetary value are deemed more valuable and might receive special incentives for repeat purchases.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "V2QPimv0chFm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6.1 Recency**"
      ],
      "metadata": {
        "id": "L3dl3u-ic0Nv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recency = Latest InvoiceDate - Last InoviceData"
      ],
      "metadata": {
        "id": "hForXzVNc-WT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group the dataset by CustomerID and find the most recent purchase date for each customer\n",
        "recency_df = Customer_df.groupby('CustomerID')['InvoiceDate'].max().reset_index().rename(columns={'InvoiceDate': 'LastPurchaseDate'})\n",
        "\n",
        "# Display the first few rows of the dataframe to inspect the results\n",
        "recency_df.head()\n"
      ],
      "metadata": {
        "id": "t0CBO43AdDGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the latest date in the dataset\n",
        "latest_date = Customer_df['Date'].max()\n",
        "\n",
        "print(latest_date)"
      ],
      "metadata": {
        "id": "daSOLpGwdcJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Calculate the recency of each customer's last purchase\n",
        "recency_df['Recency'] = recency_df['LastPurchaseDate'].apply(lambda x: (latest_date - x.date()).days)\n",
        "\n",
        "# Display the first 10 rows of the recency dataframe\n",
        "recency_df.head(10)\n"
      ],
      "metadata": {
        "id": "OcaIem_4duxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the 'LastPurchaseDate' column from the dataframe\n",
        "recency_df.drop('LastPurchaseDate', axis=1, inplace=True)\n",
        "\n",
        "# Display the first few rows of the updated dataframe\n",
        "recency_df.head()\n"
      ],
      "metadata": {
        "id": "RxfcoOtFfBKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have successfully created the \"recency\" attribute. For instance, consider a customer with the ID 12346; their most recent purchase was made 325 days ago."
      ],
      "metadata": {
        "id": "dzv1dSEzfOIT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6.2 Frequency**"
      ],
      "metadata": {
        "id": "2NwRbkb2fTkh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group the data by customer ID and count the number of invoices for each customer\n",
        "frequency_df = Customer_df.groupby('CustomerID')['InvoiceNo'].count().reset_index().rename(columns={'InvoiceNo': 'Frequency'})\n",
        "\n",
        "# Display the first 10 rows of the dataframe to inspect the results\n",
        "print(frequency_df.head(10))"
      ],
      "metadata": {
        "id": "pgr0NliFfZ4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## **6.3 Monetary Value**"
      ],
      "metadata": {
        "id": "2khRSbjIfyr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group the data by customer ID and sum the total amount spent by each customer\n",
        "monetary_df = Customer_df.groupby('CustomerID')['TotalCost'].sum().reset_index().rename(columns = {'TotalCost': 'MonetaryValue'})\n",
        "\n",
        "monetary_df.head()"
      ],
      "metadata": {
        "id": "lhoGEFOZfz73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The RFM dataframe integrates data on recency, frequency, and monetary value for each customer, offering a holistic snapshot of their engagement patterns and purchasing tendencies."
      ],
      "metadata": {
        "id": "RFBORidogXM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the recency and frequency dataframes on the customer ID column\n",
        "merged_df = recency_df.merge(frequency_df, on='CustomerID')\n",
        "\n",
        "# Display the first few rows of the merged dataframe\n",
        "print(merged_df.head())\n"
      ],
      "metadata": {
        "id": "_UJF0P3fgdYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the recency and frequency dataframes on the customer ID column\n",
        "rfm_df = recency_df.merge(frequency_df, on='CustomerID')\n",
        "\n",
        "# Display the first few rows of the merged dataframe\n",
        "print(rfm_df.head())"
      ],
      "metadata": {
        "id": "M8huC-uxgfhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Customer ID 12346, the recency of their last purchase is 325 days, with a frequency of 1 purchase. They've spent £77,183.60. This data helps us segment customers and tailor strategies for engagement and marketing."
      ],
      "metadata": {
        "id": "CZFWz-0Xh50c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6.4 Customer segments with RFM Model**"
      ],
      "metadata": {
        "id": "Pk085257iA9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To segment customers using the RFM Model, a straightforward approach is using Quantiles. Scores from 1 to 4 are assigned to Recency, Frequency, and Monetary dimensions. Higher values are better. Combining these scores creates the RFM score. While Quintiles provide more detail (1-5 scores), we use quartiles (1-4) for simplicity, as quintiles could result in 555 combinations."
      ],
      "metadata": {
        "id": "IrPIHKHbif8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the recency and frequency dataframes on the customer ID column\n",
        "rfm_df = recency_df.merge(frequency_df, on='CustomerID')\n",
        "\n",
        "# Merge the monetary value dataframe with rfm_df on the customer ID column\n",
        "rfm_df = rfm_df.merge(monetary_df, on='CustomerID')\n",
        "\n",
        "# Display the first few rows of the merged dataframe\n",
        "print(rfm_df.head())\n"
      ],
      "metadata": {
        "id": "HnPkBbhFLdVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate quantiles for the RFM dataframe\n",
        "quantiles = rfm_df[['Recency', 'Frequency', 'MonetaryValue']].quantile(q = [0.25, 0.5, 0.75])\n",
        "\n",
        "quantiles"
      ],
      "metadata": {
        "id": "VjTebmKviLOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert quantile values to dictionary\n",
        "quantiles_dict = quantiles.transpose().to_dict()\n",
        "\n",
        "quantiles_dict"
      ],
      "metadata": {
        "id": "KNgOWN8fjQ9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6.5 RFM Table & Score**"
      ],
      "metadata": {
        "id": "dNAlqPmBkQAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create RecencyScore column by dividing Recency into quartiles and assigning respective quantile labels\n",
        "rfm_df['RecencyScore'] = pd.qcut(rfm_df['Recency'], q = [0, 0.25, 0.5, 0.75, 1], labels = list(range(4, 0, -1)))\n",
        "\n",
        "# Create FrequencyScore column by dividing Frequency into quartiles and assigning respective quantile labels\n",
        "rfm_df['FrequencyScore'] = pd.qcut(rfm_df['Frequency'], q=[0, 0.25, 0.5, 0.75, 1], labels=list(range(1, 5)))\n",
        "\n",
        "# Create MonetaryScore column by dividing MonetaryValue into quartiles and assigning respective quantile labels\n",
        "rfm_df['MonetaryScore'] = pd.qcut(rfm_df['MonetaryValue'], q=[0, 0.25, 0.5, 0.75, 1], labels=list(range(1, 5)))\n",
        "rfm_df.head()"
      ],
      "metadata": {
        "id": "PGHUvJK8ki3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate the RecencyScore, FrequencyScore, and MonetaryScore columns into one RFMScore column\n",
        "rfm_df['RFMScore'] = rfm_df['RecencyScore'].astype(str) + rfm_df['FrequencyScore'].astype(str) + rfm_df['MonetaryScore'].astype(str)\n",
        "\n",
        "rfm_df.head()"
      ],
      "metadata": {
        "id": "oTAqzRy6mtts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation of RFM Scores:**\n",
        "\n",
        "- **Best RecencyScore = 4:** This indicates that the customer's last purchase was very recent, showing strong engagement with recent transactions.\n",
        "\n",
        "- **Best FrequencyScore = 4:** Customers with this score make frequent purchases, displaying a high level of loyalty and engagement.\n",
        "\n",
        "- **Best MonetaryScore = 4:** Customers with the highest monetary score are the biggest spenders, contributing significantly to the business's revenue.\n",
        "\n",
        "- **RFMScore 444:** A customer with this score has recent purchases, high frequency, and substantial monetary spending. These are the most valuable and engaged customers.\n",
        "\n",
        "- **RFMScore 111:** Customers with this score have low recency, frequency, and monetary spending. They might be at risk of churning.\n",
        "\n",
        "- **RFMScore 144:** These customers made purchases a while ago, but they buy frequently and spend more. They could be returning customers who remain engaged.\n",
        "\n",
        "- **Segmentation Possibilities:** By considering various combinations of RecencyScore, FrequencyScore, and MonetaryScore, we can create distinct customer segments. This allows us to tailor marketing strategies to each segment's unique behavior.\n",
        "\n",
        "- **Higher RFMScore, Higher Value:** Customers with higher RFMScores are generally more valuable to the business. Their recent transactions, frequency of purchases, and spending patterns make them key targets for personalized promotions and retention efforts."
      ],
      "metadata": {
        "id": "6a-_jOgSnCdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the dataframe by MonetaryValue in descending order and reset the index\n",
        "rfm_df2 = rfm_df[rfm_df['RFMScore'] == '444'].sort_values('MonetaryValue', ascending = False)\n",
        "rfm_df2.head(10)"
      ],
      "metadata": {
        "id": "8KF-b0fEl12r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Categorising customer or making customer segmentation based on RFMScore\n",
        "print('Best Customer', len(rfm_df[rfm_df['RFMScore'] == '444']))\n",
        "print('Loyal Customers: ',len(rfm_df[rfm_df['FrequencyScore'] == 4]))\n",
        "print(\"Big Spenders: \",len(rfm_df[rfm_df['MonetaryScore' ]== 4]))\n",
        "print('Almost Lost: ', len(rfm_df[rfm_df['RFMScore'] =='244']))\n",
        "print('Lost Customers: ',len(rfm_df[rfm_df['RFMScore'] == '144']))\n",
        "print('Lost Cheap Customers: ',len(rfm_df[rfm_df['RFMScore'] == '111']))"
      ],
      "metadata": {
        "id": "Ct4DjI7aiLLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Through the astute implementation of RFM segmentation, our marketing strategies attain an unprecedented precision, meticulously tailored to the distinctive behavioral patterns of each customer segment. Consider our distinguished \"Champion\" cohort – a bastion of loyalty and brand affinity. Let us honor their allegiance with exclusive rewards, while harnessing their influence as pioneers in embracing novel offerings through a strategically curated \"Refer a Friend\" initiative.\n",
        "\n",
        "In addressing the \"At Risk\" segment, we pivot with a bespoke approach. Crafted with meticulous care, personalized emails rekindle their affinity, revitalizing their engagement with our brand. This strategic maneuver is more than just retention; it's a transformation of potential attrition into renewed loyalty. Our success hinges upon an intricate understanding of, and a precise response to, the unique journey each segment undertakes."
      ],
      "metadata": {
        "id": "0kOp7BZzoIh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the RFMScore and its components columns from the dataframe\n",
        "rfm_data = rfm_df.drop(['RecencyScore', 'FrequencyScore', 'MonetaryScore','RFMScore'], axis = 1).set_index('CustomerID')\n",
        "\n",
        "# Display the first 5 rows\n",
        "rfm_data.head()"
      ],
      "metadata": {
        "id": "JDEoJWMdoF_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Feature Correlations**"
      ],
      "metadata": {
        "id": "c6YuIIDNoTD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the correlation between the variables\n",
        "rfm_data.corr()"
      ],
      "metadata": {
        "id": "RFYgASoSoXJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Correlation Heatmap**"
      ],
      "metadata": {
        "id": "PcTIivluokDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_matrix = rfm_data.corr()\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title(\"Feature Correlation Heatmap\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zbpiwxsLol6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The chosen heatmap graph serves to unveil the interrelations among various variables in a visually comprehensive manner.\n",
        "\n",
        "The analysis reveals a noteworthy negative correlation between recency and both frequency and monetary aspects, indicating that customers who have recently made purchases are less likely to engage again. Furthermore, a positive albeit mild correlation between frequency and monetary elements has been identified.\n",
        "\n",
        "These insights offer profound implications for businesses, empowering them to gain a profound understanding of customer behavior. Such understanding is pivotal for customizing sales strategies and promotional initiatives, optimizing their effectiveness and enhancing customer engagement.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kQMeLZhapOk5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Plot the distribution of Recency, Frequency, and MonetaryValue**"
      ],
      "metadata": {
        "id": "O7VT32ydpYS6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  A scatter matrix serves as a visual representation that unveils the intricate relationships between various customer behavior attributes like recency, frequency, and monetary value within the dataset. By revealing patterns, trends, and correlations, this graphical tool facilitates an in-depth exploration of how these attributes interact. This analysis provides essential insights into customer behavior patterns, aiding in the tailoring of marketing strategies to effectively engage different customer segments\n",
        "\n"
      ],
      "metadata": {
        "id": "PB0v8WNMpZqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Set the style of the pairplot\n",
        "sns.set(style=\"ticks\")\n",
        "\n",
        "# Select the columns for visualization\n",
        "columns_to_visualize = ['Recency', 'Frequency', 'MonetaryValue']\n",
        "\n",
        "# Create a pairplot\n",
        "sns.pairplot(rfm_data[columns_to_visualize], diag_kind='kde')\n"
      ],
      "metadata": {
        "id": "KQ-0xPYuqoNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The selection of a pairplot with kernel density estimation (KDE) diagonal plots is rooted in its effectiveness in capturing both the distribution and pairwise associations among numerous features. This visualization expedites the detection of correlations or patterns between variables, rendering it a premier option for comprehending feature distributions within the dataset.\n",
        "\n",
        "Observing the skewness in the distributions of the three variables underscores the need for normalization. Achieving normal distribution is imperative as it conforms to the requisites of clustering algorithms, which necessitate features to adhere to Gaussian distribution characteristics. This normalization process serves as a preparatory step towards enhanced data analysis and modeling accuracy, aligning with the project's analytical objectives."
      ],
      "metadata": {
        "id": "0rxwyQLCs2Lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The skew() method is used to measure the asymmetry of the data around the mean.\n",
        "rfm_data.skew()"
      ],
      "metadata": {
        "id": "T1gZCiuXun-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The observation underscores a significant data characteristic: the presence of skewed distributions across the three variables, coupled with the existence of outliers.\n",
        "It underscores the need for data normalization to achieve a state of normal distribution, aligning with clustering algorithms' requirements. This process enhances data suitability for advanced analysis, contributing to project analytical rigor.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Vj8yDXPhZ370"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Normalization**\n"
      ],
      "metadata": {
        "id": "20pG5Cq88f0v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logarithmic transformations were employed for normalizing the Recency and Monetary features, while a natural logarithmic transformation was applied to the Frequency feature. This approach aimed to reduce the impact of outliers and standardize the data. To avoid issues with logarithms of zero or negative values, a small constant (0.1) was added to the original values prior to transformation.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xqYecq7n8qXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the logarithmic values of the Recency and Monetary features\n",
        "rfm_df['RecencyLog'] = np.log(rfm_df['Recency'])\n",
        "rfm_df['MonetaryLog'] = np.log(rfm_df['MonetaryValue'])\n",
        "\n",
        "# Calculate the natural logarithm of the 'Frequency' column\n",
        "rfm_df['FrequencyLog'] = np.log(rfm_df['Frequency'])"
      ],
      "metadata": {
        "id": "GdLPbyoW9xT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new DataFrame with the log-transformed values\n",
        "log_df = pd.DataFrame()\n",
        "\n",
        "# Include the 'CustomerID' column in the new DataFrame\n",
        "log_df['CustomerID'] = rfm_df['CustomerID']\n",
        "\n",
        "# Add the logarithmic values of Recency, Monetary, and Frequency to the new DataFrame\n",
        "log_df['RecencyLog'] = np.log(rfm_df['Recency'])\n",
        "log_df['MonetaryLog'] = np.log(rfm_df['MonetaryValue'])\n",
        "log_df['FrequencyLog'] = np.log(rfm_df['Frequency'])\n",
        "\n",
        "# Display the first few rows of the new DataFrame\n",
        "print(log_df.head())\n"
      ],
      "metadata": {
        "id": "i4cEJE6lBVYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot the distribution of Recency, Frequency, and MonetaryValue after Data Normalization**"
      ],
      "metadata": {
        "id": "KEBD9Seq-ku_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame containing the features want to visualize\n",
        "data_for_pairplot = rfm_df[['RecencyLog', 'FrequencyLog', 'MonetaryLog']]\n",
        "\n",
        "# Create a pairplot\n",
        "sns.set(style=\"ticks\")\n",
        "sns.pairplot(data_for_pairplot, diag_kind=\"kde\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4iKDj78B-jfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "While the Frequency and Monetary features have shown noticeable improvements in their distributions and appear to be closer to a normal distribution, the Recency feature has also improved, albeit to a lesser extent. It still exhibits some deviation from the ideal normal distribution compared to the other two features."
      ],
      "metadata": {
        "id": "JuwshQFZB5Fj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_df.skew()"
      ],
      "metadata": {
        "id": "97qw_NOoC7s_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the correlation matrix for log-transformed or normalized data (log_df)\n",
        "correlation_matrix = log_df.corr()\n",
        "\n",
        "# Create a heatmap to visualize the correlations\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Features Correlation After Log Transformation or Normalization')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XTAbYbRuD0eL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the correlation matrix\n",
        "correlation_matrix = log_df.corr()\n",
        "\n",
        "# Display the correlation matrix\n",
        "print(correlation_matrix)"
      ],
      "metadata": {
        "id": "u-ieyPBLKStp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assign the normalized data to a variable \"X\"\n",
        "X = log_df"
      ],
      "metadata": {
        "id": "cCyr_grwKcur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Data Scaling***"
      ],
      "metadata": {
        "id": "6K8Fm08rKigK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Define the features to use for K-means\n",
        "features = ['RecencyLog', 'FrequencyLog', 'MonetaryLog']\n",
        "\n",
        "# Standardize the feature values\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(log_df[features].values)"
      ],
      "metadata": {
        "id": "ht3LNybLORJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}